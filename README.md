# Transformers
Repo containing a list of Transformer based projects and Tutorials


# Overview of Transformer Models

Explore some of the most impactful Transformer models, categorized by their type and usage, with links to their respective code repositories.

| **Model Name** | **Type** | **Description** | **Code Repository** |
|-------|------|----------|------|
| **PaliGemma** | Vision Language Model | A custom-built Vision Language Model integrating multimodal AI concepts.| [View Code](https://github.com/Jkanishkha0305/Transformers-from-Scratch/tree/main/PaliGemma) |
| **Stable Diffusion** | Diffusion Model | Generates detailed images from text prompts using diffusion techniques. | [View Code](#)  
| **LLaMA-2** | Text Generation Model | A cutting-edge LLM optimized for instruction-following tasks. | [View Code](#) |
| **GPT** | Text Generation Model | State-of-the-art language model for versatile text-based tasks. | [View Code](#) |
| **BERT** | Text Understanding Model | Pretrained on masked language tasks, excels in NLP understanding tasks. | [View Code](#) |
| **Vision Transformer** | Vision and Text-Image Model | Processes image data using transformer architecture for computer vision. | [View Code](#) |
| **CLIP** | Vision-Language Model | Bridges image and text modalities, enabling multimodal embeddings. | [View Code](#) |
| **Transformer-XL** | Text Generation Model | Handles long-term dependencies effectively in sequential data. | [View Code](#) |
| **RoBERTa** | Text Understanding Model | An optimized version of BERT for better pretraining efficiency. | [View Code](#) |
| **ViT-GPT2** | Vision and Text Generation  | Combines image and text generation capabilities in a single model. | [View Code](#) |

